\chapter{The ANITA-III Binned Analysis}

This chapter is a detailed description of the ANITA-III binned analysis.  Analysis of the full data set is still ongoing.  Initial results from the 10\% data set are discussed, as well as results from analysis of the low sensitivity sideband Healpix bins, and the full 90\% H-pol data. 

\section{Past Analyses}

This chapter is about a neutrino search using a binned analysis of the ANITA-III data set.  However, before this analysis, there have been several ANITA flights and different analysis methods.  Before we talk about the ANITA-III binned analysis neutrino search, this section will briefly discuss the past neutrino searches done on ANITA data sets that led to this analysis.

\subsection{Clustering Analysis}

The primary analysis performed on the ANITA-I and ANITA-II data was a clustering analysis.  The clustering analysis relies on the assumption that we do not expect many neutrino signals to be coming from the same area of the ice, while we do expect many anthropogenic signals from the same area of the ice.  When multiple events are detected from the same area of the ice, it is assumed to be a base or hot-spot for human activity, and those events are cut.  It is Abby Vieregg's ANITA-II clustering analysis that led to the ANITA Collaboration's published neutrino limits (seen in Figure \ref{fig:anita12limit}) \cite{abby}.  

\subsection{The ANITA-II Binned Analysis}

Following Abby Vieregg's ANITA-II clustering analysis, Brian Dailey worked to develop an alternative to the clustering method.  Instead of removing any events observed near other passing events, this new binned method relies on nearby events to estimate the background ANITA observes in that area of the ice.  Healpix was used to split Antarctica into roughly 50 equal-area bins, each of which had its own background estimate calculated.  Using those backgrounds, a linear discriminate cut which combined the event's SNR and correlation peak were optimized for each bin to give the strongest limit on neutrino models possible.   After setting the analysis cuts on the 10\% data sample, and analyzing the 90\% data sample, approximately 20 V-pol events were observed on an expected background of 2.6 \cite{brian}.  A neutrino limit was never set, however, the events that Brian saw passing in his 90\% dataset have informed future binned analyses on how to improve moving forward.

\section{The ANITA-III Binned Analysis}

The ANITA-III binned analysis was started by Sam Stafford in late 2016/early 2017.  It updated Brian Daily's ANITA-II Binned Analysis for the ANITA-III flight by adding additional cuts based on circular polarization information and sun reflections off the ice.  It, however, saw several events passing even in the 10\% training data set, and so it was determined that further investigation was needed before analysis could proceed to the full data set \cite{sam}.  
That is where my analysis comes in.  I have added several systematic uncertainties to the calculation of our background estimate, as well as an additional cut on events believed to have been influenced by satellite CW noise, with the help of Oindree Banerjee.  In addition, the binned analysis now has an additional layer to its optimization of the linear discriminate cut intended to incorporate the results found in all of the Healpix bins into the optimization.  The orientation of the Healpix bins has, in the past, always just been the Healpix default.  An optimization of Healpix orientation was added, to check for orientations that better fit the data ANITA-III collected during the flight.  A detailed description of the entire analysis follows.

\subsection{Healpix} 

Just as in the ANITA-II binned analysis, this analysis uses Healpix to slice Antarctica into smaller sections.  Healpix works by cutting a sphere into 12 base pixels of equal area.  Then to get finer, smaller pixels each of those 12 base pixels is cut into 4 new smaller, equal area pixels. This is repeated, yielding ever smaller sections of the sphere.  The order of a given Healpix map is the number of times the pixels have been cut into four smaller pixels \cite{Healpix}.  An order 0 Healpix map has 12 pixels.  An order 1 Healpix map has $12 \times 4=48$ pixels.  An order 3 Healpix map has $12 \times 4^3$=768 pixels.  Figure \ref{fig:healpix} gives a visual representation of the process of splitting larger pixels into smaller ones, as well as offering an example of the shape and organization of the pixels.  For our analysis, we are using an order 4 Healpix map with 3072 pixels.  We commonly refer to our pixels as Healpix bins.  All Healpix pixels are approximately equal area and organized into equal latitude rings.  

\begin{figure}[h]
\centering
\includegraphics{../figures/healpix.png}
\caption[Healpix Map]{Top left shows an order 0 Healpix map with 12 pixels.  Top right shows an order 1 Healpix map.  Bottom right shows an order 2 Healpix map, while the bottom left shows an order 3 Healpix map.  Dots represent the pixel centers.  All pixels are of equal area, and bin centers lay on equal latitude rings \cite{Healpix}.}
\label{fig:healpix}
\end{figure}
 
\subsection{Blinding Strategy and Data Sets}
To avoid biasing ourselves while setting up and optimizing our analysis cuts, we look at the data in stages.  
The first data set we use is the 10\% data set.  This dataset consists of one of every approximatly ten events spread throughout the duration of the flight.  The number of events a signle event is chosen from is randomly distributed around ten.  An event is chosen randomly from that window of approximatly ten events, then the next window of events is chosen to follow directly after the first and the process is repeated.  All of our analysis cuts are set and/or optimized on this 10\% data set.
  
The next data set, and our first step of unbinding is to look at the 90\% data set for the Healpix bins which are cut from our analysis for having low sensitivity to neutrinos.  The set of Healpix bins that contribute less than 1\% to our neutino sensitivity are set asside for this data set.  These are bins that should contain a background similar to the signal region for the 90\% dataset.  Using these few Healpix bins, the analysis cuts are tweaked and tuned to better reject background as necessary.

After this, we look at the 90\% H-pol data set.  We do not expect neutrinos in this data set, while we do expect cosmic rays.  A preliminary ANITA-III UHECR search using clustering found 20 UHECR canadites.  In order to check that our analysis is finding events of interest using this dataset, we will attempt to identify cosmic ray events using methods refined by other analyses. 

The final data set is the full 90\% V-pol data set.  At this point, our analysis cuts are set and events that pass, pass.  Assuming the number of events that pass our cuts is consistent with our background estimate, a limit on neutrino models will be set.  

Note here that we reserve the right to remove payload blast events by hand, as they are both difficult to remove from our signal with cuts, and easy to distinguish from our signal by eye.  It should also be noted that we plan on applying a clustering cut as the very last step of our analysis, and our limit will be adjusted appropriately whether we need to use it or not.

\subsection{The Calculation of Analysis Parameters}

Before events can be analyzed and potentially cut, the raw information collected by ANITA-III needs to be transformed into several important analysis parameters.  For our analysis of ANITA-III data, these parameters are calculated for all 4 polarizations, V-pol, H-pol, LCP, and RCP.

\subsubsection{ANITA Data}

The majority of the data an ANITA flight collects is stored in ANITA's payload on disks until those disks are recovered.  Once the disks are recovered the data is reformatted into a ROOT analysis database.  The database stores data in two TTree tree objects.  A header tree (headTree) stores single-valued data, such as event number, trigger time and phi sector masks.  An event tree (eventTree) contains un-calibrated time domain waveforms for all 96 data channels and 12 SURF clocks.  Other data trees store information about the payloads orientation and position, and data from onboard temperature and voltage sensors \cite{sam}.

\subsubsection{Filtering}

ANITA-III saw persistent CW noise throughout its flight.  One method for dealing with this is by filtering the raw waveforms received from eventTree.   The Geometric Filter developed by Brian Dailey \cite{brian} is used to do this.  The Geometric Filter looks at the waveform in the frequency domain and notches out the peak power.  An event is flagged for filtering if any of the frequency bins in its amplitude spectrum are more than 4 dB above a baseline sample for that antenna.  Any fequency bins that meet this criteria are included in the filtered band.  CW noise appears as a strong peak in the frequency domain, while the impulsive signals ANITA searches for are spread out in the frequency domain.  This approach is somewhat analogous to ANITA-IV's TUFFs, discussed in Chapter \ref{ch:tuff}.  Though the Geometric Filter acts well after triggering in software, while the TUFFs filter in real time, in hardware, before triggering.  The power spectrum in the frequency band that is notched out is filled in to  prevent artifacts when transforming the signal back into the time domain.  The Geometric Filter also subtracts off the CW phasor from the total phasor in each frequency bin to correct the phase for the removal of the CW contribution.  Figure \ref{fig:geoFilter} shows an example of a pre-filtered power spectrum and phases in black, and the same after filtering in red.  After filtering, interferometry is performed on the waveforms.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\linewidth]{../figures/geoFilter.png}
\caption[Geometric Filter]{Top shows the geometric filter at work removing a CW peak from a frequency domain gain waveform.  The waveform is in black, while the waveform after filtering is in red.  The geometric filter's fit to the CW noise is in blue.  Bottom shows the same thing for the frequency domain phase \cite{brian}.}
\label{fig:geoFilter}
\end{figure}


\subsubsection{Interferometry, Finding the Arrival Direction of Signals}

Any two of ANITA's antennas that see the same impulsive signal should have some time delay between the observed signals.  It just takes the signal slightly longer to reach one of the antennas that it does to reach the other.  The length of that time delay can be used to narrow down the direction that the signal originated from, as shown in Figure \ref{fig:skyCir}.  Every additional antenna that sees a signal offers additional pointing information.  In a perfect world, with no noise mixed into a signal, just three antennas seeing an impulsive signal would be enough to point back to where that signal came from.  In practice, however, finding the time delay between antennas is not trivial.  ANITA usually observes a strongly impulsive signal with between 6-12 antennas \cite{sam}.  Using all of the different antenna pairs, the arrival direction is determined as best as possible by summing all of the correlation maps found from individual antenna pairs and choosing the point with the highest correlation value as the arrival direction.  Individual correlation maps are found by finding how well two waveforms corrolate for varying time delays between them.  Those time delays are then converted into a circle in $\phi$ and $\theta$.  This event pointing from the summed correlation map is the event pointing used in our analysis cuts.  Figure \ref{fig:corMapExp} shows an example of the correlation map from a calibration pulser.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\linewidth]{../figures/skyCir.png}
\caption[Antenna Correlation Circle]{Figure displays the circle that can be drawn using two antennas with a baseline b and a time delay of $\Delta \tau$ between the arrival time of the signal \cite{sam}.}
\label{fig:skyCir}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.6\linewidth]{../figures/corrMapExp.png}
\caption[Correlation Map Example]{The top shows the correlation map from an WAIS calibration pulse \cite{sam}.}
\label{fig:corMapExp}
\end{figure}


\subsubsection{Correlation Peak}

The value at the peak of this summed correlation map is the correlation peak used in our analysis cuts.

\subsubsection{SNR}

Once the arrival direction is determined, from all pairs, each antenna pair has a time delay determined from that arrival direction.  Coherently summed waveforms are created by adding together the individual waveforms with the correct time delays for the arrival direction. The signal-to-noise ratio of an event is calculated from the coherently summed waveforms of that signal.  ANITA-III saw ringing after impulsive signals, so the time before the impulsive signal was used to estimate the noise of the signal from a 10~ns window.  Figure \ref{fig:snrCalc} shows the 10~ns window used to calculate the noise, while the signal is calculated as one half of the peak-to-peak amplitude of the pulse.

\begin{figure}[h]
\centering
\includegraphics{../figures/snrCalc.png}
\caption[SNR Noise and Signal Sampling]{Figure shows a waveform from a calibration pulse.  The blue box shows the region used to calculate the noise of the waveform, while the green line shows the average value averaged over all waveforms \cite{sam}.}
\label{fig:snrCalc}
\end{figure}


\subsubsection{Hilbert Peak}

If the observed coherently summed waveform is $V(t)$, then the magnitude of the analytic signal of $V(t)$, $A(t)$ is a measure of its instantaneous power \cite{sam}.  $A(t)$ is defined in equation \ref{eq:A(t)}

\begin{equation} \label{eq:A(t)}
A(t) = V(t) + iH(t)
\end{equation}

Where $H(t)$ is the Hilbert transform of V(t).  The Hilbert peak is then the peak in the magnitude of $A(t)$.

\subsubsection{Healpix bin and Healpix weight}

One of the features of the binned analysis is that we split events into different Healpix bins.  The Healpix bin in which an event falls is determined by tracing its reconstruction direction back to the surface of Antarctica.  Using functions written in ANITATools by Ryan Nichol, and BEDMAP2, a dataset of the surface elevation of Antarctica, the location at which the event came out of the ice is found.  This location in longitude and latitude can be used to locate which Healpix bin an event falls in.  Events that are very close to the boundary between Healpix bins are assigned a weight based on how much of a one-standard-deviation error ellipse around the event, based on uncertainty in the event's reconstructed angels, is inside of the Healpix bin.  Events that fall entirely inside of one Healpix bin have a weight of one.  

\subsection{Quality Cuts}

Now that I have described our main analysis parameters, and how they are found, we can talk about our analysis cuts.  Quality cuts are the very first stage of cuts.  They are used to remove events that prevent effective interferometry.   The quality cuts remove about 50\% of recorded events while removing about 25\% of simulated neutrinos with an SNR greater than 5.0.  Most of these simulated neutrinos are being cut by our current payload blast cut.  Table \ref{tab:qcuts} shows the events cut in both V- and H-pol for all of the quality cuts.  Table \ref{tab:qcutsSim} shows the number of simulated neutrino events cut in both V- and H-pol by the quality cuts.

\subsubsection{No Trigger Cut}

The No Trigger Cut just requires the recorded event to have a triggering phi sector.  If the event did not cause a phi sector to trigger, then it is cut.

\subsubsection{Trigger Type Cut}

This cut requires the trigger type to be a radio frequency (RF) trigger.   Events that are not RF triggers are cut.
 
\subsubsection{SURF Saturation Events}

The SURF's operating range only extends up to 1.5 V.  If an event's waveform goes beyond that operating range, it can become distorted\cite{abby}.  Due to this, events with more than three waveforms that exceed 1.5 V are cut.
\subsubsection{DC-Offset Events}

Some events have waveforms with noticeable DC offsets.  This is thought to be due to digitization problems\cite{abby}.  If an event has a mean value in their waveform of greater than 100 mV in any channel, it is cut.  

\subsubsection{Short-trace Events}

A complete waveform in ANITA-III has 240 data entries or samples.  If an event has less than 240 samples for any reason, it is considered incomplete and cut.

\subsubsection{Payload Blast Events}

Payload blast events are events that appear to be coming from behind ANITA's antennas from the payload itself.  They are both impulsive and often have a high SNR. Because of these features, payload blast events can be quite problematic to our analysis.  Both this cut and the nadir noise events cut are designed to remove payload blast events.  This cut removes events that L3 trigger across 6 or more phi sectors.  Payload blasts are able to trigger many channels spread out dramatically in direction because they come from behind the antennas, the direction the individual antennas are facing does not matter much when the source is so near.

\subsubsection{Nadir Noise Events}

Though ANITA-III does not have a true `Nadir' ring now that the experiment's bottom ring has been updated to include 16 antennas, just like the middle and top rings, this cut is the same as it was in Abby's and Brian's ANITA-II analysis.  Thus the name has not changed.  This cut is designed to remove events with significantly more power in the bottom ring than in the top ring, another characteristic of an event very near the antennas.  If the maximum peak voltage in the bottom ring, is less than one half the maximum peak voltage in the top ring, the event is cut.

\begin{table}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/qCuts.png}
\caption[Quality Cuts Table]{This table shows the number of events cut by each of the quality cuts.  `As first cut' shows the amount cut by that quality cut if it takes place first.  `As ordered cut' shows the amount cut by that quality cut if it takes place in order.  `As last cut' shows the amount cut by that quality cut if it takes place as the last quality cut.  The number columns are the number of events cut, while the fraction columns show the fraction of events cut.}
\label{tab:qcuts}
\end{table}

\begin{table}[h]
\centering
\fbox{
\includegraphics[width=0.8\linewidth]{../figures/qCutsSim.png} }
\caption[Quality Cuts Table for Simulated Events]{This table shows the number of simulated events with an SNR $>$ 5 cut by each of the quality cuts.  `As first cut' shows the amount cut by that quality cut if it takes place first.  `As ordered cut' shows the amount cut by that quality cut if it takes place in order.  `As last cut' shows the amount cut by that quality cut if it takes place as the last quality cut.  The number columns are the number of events cut, while the fraction columns show the fraction of events cut.}
\label{tab:qcutsSim}
\end{table}

\subsection{Stage 1 Analysis Cuts}

Stage 1 analysis cuts are the first stage of analysis cuts.  They are direction based, removing events that reconstruct in directions from which we should not see neutrinos, or directions from which we expect to see a large amount of noise.  Table \ref{tab:a1cuts} shows the number of events (which survived the quality cuts) cut by any of the Stage 1 analysis cuts.  Table \ref{tab:a1cutsSim} shows the number of simulated events with an SNR greater than 5.0 cut by and of the Stage 1 analysis cuts.  Stage 1 analysis cuts remove about 95\% of events while removing about 30\% of simulated neutrinos with an SNR greater than 5.0.  This allows for much faster data processing in subsequent steps of the analysis.

\subsubsection{Solar Reflection Cut}

The reflection of the sun off of the ice is a hot spot for noise events \cite{sam}.  Events that point to within 5 degrees of the sun's reflection are cut.

\subsubsection{Localization to Continent Cut}

For this ANITA-III neutrino search, we only expect to see neutrino signals from the ice.  Thus events that do not reconstruct back to the continent are cut. 

\subsubsection{Elevation Angle Cut}

ANITA-III's antennas have a 6dB fall off at 22.5 degrees, and the point to 10 degrees below the horizon.  This means any signals arriving from below -35 (slightly more than 22.5 + 10) degrees should be greatly reduced in power.  Many of the events we do see from those angles are misreconstructions.   Events that reconstruct to angles above the continent are similarly thought to be misreconstructions \cite{abby}.  Events that reconstruct to above 6.0 degrees below the horizon, or below 35.0 degrees below the horizon are cut.

\subsubsection{Triggering Phi-sector direction Cut}

Another sign of a misreconstruction is an event that reconstructs to a phi sector in which it did not cause an L3 trigger.  Events that do not trigger in the phi sector they reconstruct into, are cut. 

\subsubsection{Calibration Pulsar Cut}

Events originating from WAIS and LDB are cut if their nanosecond time-stamp is consistent with the calibration pulsars at those locations.

\begin{table}[h]
\centering
\includegraphics[width=\linewidth]{../figures/a1Cuts.png}
\caption[Stage 1 Analysis Cuts Table]{This table shows the number of events cut by each of the Stage 1 analysis cuts.  `As first cut' shows the amount cut by that analysis cut if it takes place first.  `As ordered cut' shows the amount cut by that analysis cut if it takes place in order.  `As last cut' shows the amount cut by that analysis cut if it takes place as the last stage 1 analysis cut.  The number columns are the number of events cut, while the fraction columns show the fraction of events cut.}
\label{tab:a1cuts}
\end{table}

\begin{table}[h]
\centering
\fbox{
\includegraphics[width=0.95\linewidth]{../figures/a1CutsSim.png} }
\caption[Stage 1 Analysis Cuts Table for Simulated Events]{This table shows the number of simulated events with an SNR greater than 5.0 cut by each of the Stage 1 analysis cuts.  `As first cut' shows the amount cut by that analysis cut if it takes place first.  `As ordered cut' shows the amount cut by that analysis cut if it takes place in order.  `As last cut' shows the amount cut by that analysis cut if it takes place as the last stage 1 analysis cut.  The number columns are the number of events cut, while the fraction columns show the fraction of events cut.}
\label{tab:a1cutsSim}
\end{table}
  
\subsection{Stage 2 Analysis Cuts}

Stage 2 analysis cuts remove events with characteristics in their SNR, correlation peak or Hilbert peak that are not consistent with neutrino signals.  Table \ref{tab:a2cuts} shows the number of events (which survived the Stage 1 analysis cuts) cut by any of the Stage 2 analysis cuts.  Table \ref{tab:a2cutsSim} shows the number of simulated events with an SNR greater than 5.0.  The Stage 2 analysis cuts remove about 73\% of events while removing about 15\% of simulated neutrinos with an SNR greater than 5.0.  

\subsubsection{Ratio of Highest Peak Cut}

Neutrino signals are expected to be highly impulsive, which is expected to render as a single distinct peak in the correlation map (though there are counter examples of this not being true).  CW and thermal noise, however, are expected to produce multiple peaks \cite{sam}.  If the ratio of the second largest to largest peak in the correlation map is less than 0.9, then the event is cut. 

\subsubsection{Correlation Peak Cut}

A highly impulsive event should have a large peak value on its correlation map \cite{sam}.  Events with a correlation peak value below 0.04 are cut.  

\subsubsection{Hilbert Peak Cut}

Impulsive events should have the majority of their power concentrated over a small window in time.   They should also have a high peak power value within that time window.  The Hilbert peak is a measure of both of these.  Events with a Hilbert peak value below 25 are cut. 

\subsubsection{Satellite Stripe Cut}

Noise from geostationary military satellites is a significant problem for ANITA-III.  To counteract this, a new analysis cut was developed.  It is believed that satellite CW noise boosts the correlation peak values of events and biases their reconstruction towards the satellite's location.  This effect can be seen in Figure \ref{fig:satStripes}.  When events are plotted in an event $\phi$ reconstruction direction vs ANITA's payload longitude plot, distinct stripes in the density of the map are observed.  These stripes are strongest when looking at the reconstructed $\phi$ in the LCP, which is the same as the polarization of the satellite's CW noise.  At some longitudes, certain satellites are not observable to ANITA's payload, and thus the stripes associated with those satellites drop out of Figure \ref{fig:satStripes}.

\begin{figure}[h]
\centering
\includegraphics{../figures/satStripes.png}
\caption[Satellite Stripes]{Image shows the increased density of events at specific linear combinations of payload longitude and event phi.  These over densities appear as stripes in the plot.  This effect is believed to be caused by satellite influence.  The same effect shown here in ANITA-II's R-pol can be observed in ANITA-III's L-pol. An ANITA-II image is shown here because the stripes are more well defined in the 90\% sample than in the 10\%.  Figure made by Oindree Banerjee.}
\label{fig:satStripes}
\end{figure}

To remove events affected by this satellite contamination, we cut events which fall within one of these satellite stripes, and are stronger in LCP than in RCP in their correlation peak, and the satellite is visible to ANITA when the event was observed are cut.  The ratio of LCP/RCP that is cut on varies between stripes, but for most stripes is approximately 1.5.

\begin{table}[h]
\centering
\includegraphics[width=\linewidth]{../figures/a2Cuts.png}
\caption[Stage 2 Analysis Cuts Table]{This table shows the number of events cut by each of the Stage 2 analysis cuts.  `As first cut' shows the amount cut by that analysis cut if it takes place first.  `As ordered cut' shows the amount cut by that analysis cut if it takes place in order.  `As last cut' shows the amount cut by that analysis cut if it takes place as the last Stage 2 analysis cut.  The `number' columns are the number of events cut, while the `fraction' columns show the fraction of events cut.}
\label{tab:a2cuts}
\end{table}

\begin{table}[h]
\centering
\fbox{
\includegraphics[width=0.95\linewidth]{../figures/a2CutsSim.png} }
\caption[Stage 2 Analysis Cuts Table for Simulated Events]{This table shows the number of simulated events with an SNR greater than 5.0 cut by the any of the Stage 2 analysis cuts.  `As first cut' shows the amount cut by that analysis cut if it takes place first.  `As ordered cut' shows the amount cut by that analysis cut if it takes place in order.  `As last cut' shows the amount cut by that analysis cut if it takes place as the last Stage 2 analysis cut.  The `number' columns are the number of events cut, while the `fraction' columns show the fraction of events cut.}
\label{tab:a2cutsSim}
\end{table}

\subsection{Final Analysis Cuts} \label{subsec:facuts}

The final analysis cuts include any analysis cuts that have been optimized for, or that need to happen after the optimization of other cuts.  This includes the binned analysis's main cut, the linear discriminate cut.  Table \ref{tab:afcuts} shows the number of events (which survived the stage 2 analysis cuts) cut by any of the final analysis cuts.  Table \ref{tab:afcutsSim} shows the number of simulated events (with an SNR greater than 5) cut by the first few final cuts.  The final analysis cuts remove about 99.9\% of surviving events while removing only about 10\% of simulated neutrinos with an SNR greater than 5.0 (Though note, this number does not include events cut by the LD cut or the Healpix bin cut, while the number of surviving data events does).

\subsubsection{Circular polarization Peak Separation Cut}

The threshold for the circularly polarized peak separation cut was optimized for by Sam Stafford, as described in section \ref{subsubsec:slopeOptimization}, for the ANITA-III binned analysis.  This cut removes an event if the correlation peak in LCP is more than 46 degrees from its correlation peak in RCP.

\subsubsection{Circular polarization Peak Strength Cut}

Like the circular polarization peak separation cut's threshold, the threshold for the circular polarization peak strength cut was also optimized for by Sam Stafford, as described in Section \ref{subsubsec:slopeOptimization}.  An impulsive event in V-pol should have its power split up evenly between LCP and RCP.  The cut removes an event if either the LCP or RCP peak is below 0.015.  In practice, these two circular polarization cuts primarily remove thermal noise.  There is no reason for thermal noise to have a correlation in peak reconstruction direction or in strength between any of their polarizations.

\subsubsection{Linear Discriminate Cut}

The Linear Discriminate (LD) cut is this analysis's main cut.  If the linear discriminate value for a given event is below some threshold (usually referred to as the cutVal) than the event is cut.  The linear discriminate value is a linear combination of the event's SNR and correlation peak value and is defined as shown in Equation \ref{eq:linearDiscriminate}

\begin{equation} \label{eq:linearDiscriminate}
\textrm{Linear discriminate} = \textrm{SNR} - \textrm{slope} \cdot \textrm{Correlation Peak} 
\end{equation}

The slope in Equation \ref{eq:linearDiscriminate} was optimized for by Sam Stafford as described in Section \ref{subsubsec:slopeOptimization} and is -6.0.  The value for cutVal is optimized separately for each Healpix bin, as described in Sections \ref{subsubsec:optLDcut} and \ref{subsubsec:optLDCutOverall}.

\subsubsection{Cut on events in cut Healpix bins}

Individual Healpix bins can be cut for several different reasons.  If an event is in a Healpix bin that is cut, then that event is also cut. 

The first cause for a Healpix bin to be cut is if it does not have at least 5 bins (histogram bins, not Healpix bins) with data to be fit to obtain our background estimate with the process described in Section \ref{subsec:bgEstStart}.  If we cannot get a background estimate for a Healpix bin it is not possible to use that bin to set a neutrino limit.

The second cause for a Healpix bin to be cut is if the fit found from the process described in Section \ref{subsec:bgEstStart} returns a bad p-value.  The process of finding a fit's p-value is described in Section \ref{subsubsec:pval}.  If the p-value for a Healpix bin's fit is less then 0.05, or greater than 0.999 then we do not consider the fit good enough to accurately represent the data, and the Healpix bin is rejected.

The third cause for a Healpix bin to be cut is if the Healpix bin has a background estimate greater than 1.0.  If the background estimate for an individual bin is that large, then that Healpix bin will not be able to help us set a better limit, and is thus cut.

The fourth and final cause for a Healpix bin to be cut is if the Healpix bin has very low neutrino sensitivity.  We base our estimate for neutrino sensitivity for a Healpix bin off of how many simulated neutrinos passing all cuts before our linear discriminate cut are coming from that area of the ice.  More simulated neutrinos mean that area of the ice is more sensitive to neutrinos.  The least sensitive Healpix bins with cumulative sensitivity of less than 1\% (after all previous Healpix bin cuts) are removed for low sensitivity.   These few Healpix bins are used as a sideband in the analysis.

Figure \ref{fig:binStatus} shows a map of which Healpix bins are kept, and for what reason the other Healpix bins are cut overlaid on top of an outline of Antarctica.  Twenty-two Healpix bins are kept in the V-pol channel analysis.  Twelve Healpix bins are kept in the H-pol channel analysis. 

\begin{figure}
\centering
    \subfloat[Status of Healpix bins in the V-pol channel analysis. \label{fig:binStatV}]{%        
            \includegraphics[width=0.45\textwidth]{../figures/hpBinStatus_175_439_V} 
    }
    \hfill
     %add desired spacing between images, e. g. ~, \quad, \qquad etc.
      %(or a blank line to force the subfigure onto a new line)
    \subfloat[Status of Healpix bins in the H-pol channel analysis. \label{fig:binStatH}]{%
            \includegraphics[width=0.45\textwidth]{../figures/hpBinStatus_175_439_H} 
    }
    \caption[Healpix bin Status]{Blue Healpix bins are kept in the analysis.  All others are cut for various reasons identified by their color.  The light blue/gray Healpix bins cut for low sensitivity will later be used as a sideband before examining the full 90\% data set.}
    \label{fig:binStatus}
\end{figure}


\subsubsection{Cut on events with a weight less than 0.5}

Events with an event weight of less than 0.5 are cut.  An event weight of less than 0.5 corresponds to the event being less than 50\% likely to have come from the Healpix bin it is seen passing in.  We want passing events to pass in the Healpix bin they are mostly within.

\begin{table}[h]
\centering
\includegraphics[width=\linewidth]{../figures/afCuts.png}
\caption[Final Analysis Cuts]{This table shows the number of events cut by each of the final analysis cuts.  `As first cut' shows the amount cut by that analysis cut if it takes place first.  `As ordered cut' shows the amount cut by that analysis cut if it takes place in order.  `As last cut' shows the amount cut by that analysis cut if it takes place as the last final analysis cut.  The `number' columns are the number of events cut, while the `fraction' columns show the fraction of events cut.}
\label{tab:afcuts}
\end{table}

\begin{table}[h]
\centering
\fbox{
\includegraphics[width=0.95\linewidth]{../figures/afCutsSim.png} }
\caption[Final Analysis Cuts Table for Simulated Events]{This table shows the number of simulated events with an SNR greater than 5.0 cut by the first few of the final analysis cuts.  `As first cut' shows the amount cut by that analysis cut if it takes place first.  `As ordered cut' shows the amount cut by that analysis cut if it takes place in order.  `As last cut' shows the amount cut by that analysis cut if it takes place as the last final analysis cut.  The `number' columns are the number of events cut, while the `fraction' columns show the fraction of events cut.}
\label{tab:afcutsSim}
\end{table}

\subsection{Background estimate} \label{subsec:bgEstStart}

A crucial component of the binned analysis is obtaining an estimate of the expected background for each Healpix bin.  In order to do this, we would like to fit a function that matches the distribution of events observed passing our quality cuts and analysis cuts.  This background estimate combined with our simulated dataset will help us inform where to place our main cut, the linear discriminate cut.  Due to its relationship with the linear discriminate cut we represent the data at this stage of the analysis as a histogram events LD values, as shown in Equation \ref{eq:ldval}.

\begin{equation} \label{eq:ldval}
LD =  \textrm{SNR} - LD_{slope} \cdot \textrm{Correlation Peak} 
\end{equation}

How $LD_{slope}$ was determined will be addressed in detail in section \ref{subsubsec:slopeOptimization}.  The SNR is the signal to noise ratio of the event's peak for the given polarization.  The Correlation Peak is the peak correlation value for the given polarization.  Figure \ref{fig:diffplot} shows an example of the data being fit, along with an exponential fit to the data.

\begin{figure}[h]
\centering
\includegraphics{../figures/diffplot.png}
\caption[Exponential Fit Example]{Figure shows an example of the $LD$ histogram being fit by an exponential decay function for Healpix bin 3004 in the V-pol channel.  Data points are in blue.  The best fit is in red.  The vertical red line is the optimized y-intercept cut threshold for the linear discriminate cut (before the overall optimization).}
\label{fig:diffplot}
\end{figure}

The Functional form chosen to fit the observed distributions is an exponential decay.  During the original ANITA-II Binned Analysis, it was observed that the data fell off very quickly for higher values of $LD$ and the fall off after the peak appeared to be linear on a log plot.  Both of these features match the characteristics of an exponential decay.  

The data was fit from the second data point after the peak of the histogram, out to include up to 23 histogram bins with zero data.  The number of trailing zeros was chosen such that the fit would not change with the addition of more trailing zeros.  The data was fit by the functional form shown in equation \ref{eq:expofit} where $a$ and $b$ are the two fit parameters, and x is the x-axis value, or the linear combination of correlation peak and SNR from Equation \ref{eq:ldval}.

\begin{equation} \label{eq:expofit}
f(x) = e^{a+b \cdot x}
\end{equation}

 The data is fit using the Minuit2 migrad minimization, where the equation being minimized is a negative log-likelihood equation assuming Poisson-like, non-integer values.  

\begin{equation} \label{eq:fitLikelihood}
L = f(x_i) - y_i + y_i \cdot \ln{\frac{y_i}{f(x_i)}}
\end{equation}

Where $x_i$ and $y_i$ represent the x-axis, and y-axis values for the ith data point as seen in Figure \ref{fig:diffplot}.  The likelihood shown in Equation \ref{eq:fitLikelihood} has been simplified using the first few terms of an expansion.  Values for $a$, $b$, $\sigma _a$ and $\sigma _b$ are obtained from the migrad fitting algorithm.  

Once the best fit has been determined, and the y-intercept for the linear discriminate cut has been chosen, the background is obtained by integrating the best fit function from the linear discriminate cut to infinity.  Assuming the parameter $b$ has a negative value, which it always should for a decaying exponential, the integral can be simplified down into equation \ref{eq:bgEst}, where V (referred to as cutVal in text) is the y-intercept of the linear discriminate cut.

\begin{equation} \label{eq:bgEst}
bg = \frac{-1}{b} \cdot e^{a+b \cdot V}
\end{equation}

In our ANITA-III Binned Analysis, we obtain our background estimates from a 10\% data set, so to obtain a background estimate for the number of events we expect passing, for a given Healpix bin in the 90\% dataset, we multiply the result of Equation \ref{eq:bgEst} by a factor of 9. 

\subsubsection{Fit Validation: p-values \label{subsubsec:pval}}

In order to use our exponential fit as a background estimate, it is important to validate that our data is consistent with our model.  To do this, we do a p-value test.  We generate many sets of pseudo-experiment data by treating the exponential fit as a probability distribution.  Each pseudo experiment has the same number of events as the actual fit data does.  The likelihood of the original exponential fit fitting this new pseudo data is then found.  

\begin{equation}
L = \sum_i f(x_i) - y_i + y_i \cdot \ln \frac{y_i}{f(x_i)}
\end{equation}

Where $x_i$ and $y_i$ are the x and y coordinates of the ith data point, and $f(x)$ is the value returned by the fit at an arbitrary position $x$.
The percentage of pseudo-experiments that return a lower log likelihood value than our original fit is then calculated, and that is our p-value.  Figure \ref{fig:pvalLike} shows an example of a histogram created from pseudo-experiments' log-likelihood values.  The red line is the log-likelihood value calculated from that Healpix bin's actual data.  

Figure \ref{fig:pvalDist} shows the distribution of p-values found for all Healpix bins with sufficient data to be fit.  If our exponential fit is a good model of the data then one would expect a flat distribution of p-values, which appears to be what we observe (for Healpix bins with a p-value greater than 0.05). 

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/pvalLike.png}
\caption[P-value Pseudo Experiments Histogram]{Plot shows a histogram of log likelihood values for p-value pseudo experiments.  The original fits log likelihood is the red vertical line.  This plot is from Healpix bin 3004 in the V-pol channel.}
\label{fig:pvalLike}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics{../figures/pvalDist.png}
\caption[P-value Histogram]{Plot shows a histogram of p-values found from different Healpix bins in the V-pol analysis channel.  Healpix bins which were not fit due to insufficient data are plotted as having a 0 p-value here, so the first bin should be ignored.  The approximately flat nature of this histogram implies that an exponential fit is a good model of our data.}
\label{fig:pvalDist}
\end{figure}
 
\subsection{Background Estimate Systematic Uncertainty}

There is a lot of uncertainty that comes from this background estimate, however.  First of all, the data is not perfectly fit by an exponential decay.  This means there are uncertainties in the fit parameters which can be propagated on into uncertainties in the background estimate.  

Additionally, we used a 10\% data set to create our background estimate and it is possible that the events in the 90\% dataset will not fall in exactly the same Healpix bins, thus altering our expected number of events in each bin.  We try to take account of this by calculating the possible spillover of events between bins.

We also attempt to account for any bias created by our specific choice of our fit model.  We chose an exponential function.  To attempt to account for any uncertainty from this choice we compare our background estimates from an exponential fit with the background estimates we would obtain for a power law fit.

\subsubsection{Fit Parameter Uncertainty}

Using Minuit2 we obtain the uncertainty in both of our fit's parameters.  These two parameters however, are not only correlated, but it is also possible that their uncertainties are not symmetric.  To take into account these complications when propagating the parameter uncertainties to the background estimate, instead of relying on the default parameter uncertainties, from ROOT or Minuit2, we obtain the one standard deviation error contour from Minuit2.  This gives us an error ellipse for the two parameters.

Due to the non-linearity of the relationship between the fit parameters and the background estimate, instead of analytically propagating the errors, we simply use simulation to find the uncertainty in the background.  In order to do this, we need to create a two-dimensional probability distribution function to draw random parameter values from, taking into account their correlation.  Using the error ellipse from Minuit2 we can do this following the procedure outlined in Appendix \ref{ch:app3}.

To calculate the uncertainty due to the parameters, we draw N pairs of fit parameters from the two-dimensional PDF, and calculate the background estimate those parameters give.  This results in a distribution of N different random background estimates.  To find the one-standard-deviation error bars, we produce a CDF of the background distribution.  The lower background limit is the value where 15.8\% of the background distribution is below that value.  Similarly, the upper background limit is the value where 84\% of the background distribution is below that value.  These error bars are reported but not actually used.  The background distributions created from this method, however, are then further modified by the other systematic uncertainties.

\subsubsection{Uncertainty due to Spillover of events between Healpix Bins} \label{subsubsec:spillover}

If every event in the 10\% dataset represents nine events in the 90\% data set, then we expect those other nine events to be distributed in an area around the 10\% dataset event.  This means that some of those nine events could point back to different Healpix bins.  In order to account for that possibility in our background estimate, we calculate the spillover between bins.

The first step in calculating the spillover is to, for each event (that has passed our quality and analysis cuts), create a grid in $\theta$ and $\phi$ around the event's actual $\theta$ and $\phi$.  ANITA-III has an uncertainty in $\phi$ of approximately 0.5 degrees, and an uncertainty in $\theta$ of approximately 0.25 degrees \cite{brian}.  Uncertainties in $\theta$ and $\phi$ are assumed to be Gaussian \cite{brian}.  In order to densely sample the $\phi$-$\theta$ space, a grid spacing of one-tenth of those uncertainties is chosen.  Grid points extend out to a 4 $\sigma$ level.  This results in an oval of grid points around the actual event pointing.  Each grid point has a probability associated with it.  The probability, $P(G,P)$, is the chance that an event at the grid point G could mistakenly be reconstructed to point back to the direction ANITA found, P.  

\begin{equation}  \label{eq:spillP}
P(G,P) = \frac{1}{2\pi \cdot \sigma_{\phi} \cdot \sigma_{\theta}} \exp(-\frac{(\theta _G - \theta _P)^2}{ \sigma_{\theta}^2
} -\frac{(\phi _G - \phi _P)^2}{ \sigma_{\phi}^2})
\end{equation}

Where $\theta _G$ and $\phi _G$ are the $\theta$ and $\phi$ at the grid point G.  $\theta _P$ and $\phi _P$ are the $\theta$ and $\phi$ at the event reconstruction P.  $\sigma_{\theta}$ and $\sigma_{\phi}$ are the uncertainty in $\theta$ and $\phi$.  

Each grid point is then ray traced back to the Antarctic continent to find where a signal coming from that direction would have left the ice.  This results in a latitude and longitude for the grid point.  The Healpix bin corresponding to each grid point is obtained using built-in Healpix functions.

Each $\phi$-$\theta$ on the grid is multiplied by a factor to take into account the area on the earth that that grid point is representing.  This is done because we are assuming that events are distributed evenly on the ice, not evenly in ANITA's $\phi$-$\theta$ coordinate system. This is found by converting the position for each grid point into easting and northing, then finding the distance from any individual grid point to the grid points around it.  For example, if the grid index for $\phi$ is $i$ and the index for $\theta$ is $j$, then the factor the grid point G$_{ij}$ would be multiplied by would be:

\begin{equation} \label{eq:spillA}
\begin{split}
A_{i j} = &\frac{\sqrt{(n_{i j}-n_{i-1 j})^2+(e_{i j}-e_{i-1 j})^2} + \sqrt{(n_{i j}-n_{i+1 j})^2+(e_{i j}-e_{i+1 j})^2}}{2} \\
& \cross \\ 
&\frac{\sqrt{(n_{i j}-n_{i j-1})^2+(e_{i j}-e_{i j-1})^2} + \sqrt{(n_{i j}-n_{i j+1})^2+(e_{i j}-e_{i j+1})^2}}{2}
\end{split}
\end{equation}

Where $n_{i j}$ is the northing of grid point G$_{i j}$, and $e_{i j}$ is the easting of grid point G$_{i j}$.  If a given grid point does not have a neighboring grid point in one of the directions around it, the above equation is modified to take that into account and base that dimension of $A_{i j}$ off of only one neighboring grid point instead of both its neighbors.  Once each grid point for a given event has been multiplied by the area it represents, the probability density function is normalized to one.  The final probability for any given point grid point G$_{i j}$ is then:

\begin{equation}
N_{i j} = \frac{P_{i j} \cdot A_{i j}}{\sum_i \sum_j P_{i j} \cdot A_{i j}}
\end{equation}

Where $P_{i j}$ is calculated from Equation \ref{eq:spillP} and $A_{i j}$ is calculated from equation \ref{eq:spillA}.  This value is the probability of an event in the 90\% sample represented by an event in the 10\% sample at the center of the grid, to be at grid point G$_{i j}$.

The probabilities from a given event's grid points that fall within the same Healpix bin are then summed together and stored in an indexed map, indexed by Healpix bin.  This is done for all events that have passed all cuts before the Linear Discriminate cut. 

Once all of the events' spillover contributions have been added into the indexed map a final normalization is done.  This normalization requires the total probability contribution from any Healpix bin to its neighbors and itself to add up to one.  After this final normalization, to find the background uncertainty contribution of Bin X to Bin Y, you would multiply Bin X's background estimate by Bin X's probability contribution to Bin Y.  Table \ref{tab:spillTable} shows an example of three Healpix bin's contributions to themselves and their neighbors.  
 
\begin{table}[]
\centering
\begin{tabular}{||l|l||l|l||l|l||}
\hline
\hline
\multicolumn{2}{||c||}{Healpix bin 2967}              & \multicolumn{2}{c||}{Healpix bin 2968}               & \multicolumn{2}{c||}{Healpix bin 2969} \\ \hline
Receiving Bin            & Cont            & Receiving Bin            & Cont            & Receiving Bin     & Cont     \\ \hline  \hline
2967                     & 0.9904                   & 2968                     & 0.9868                   & 2969              & 0.9285            \\ \hline
2966                     & 0.0037                   & 2995                     & 0.009                    & 2995              & 0.0583            \\ \hline
2994                     & 0.0037                   & 2994                     & 0.0039                   & 2970              & 0.0075            \\ \hline
2936                     & 0.0013                   & 2969                     & 0.0002                   & 2996              & 0.004             \\ \hline
2937                     & 0.0009                   & \cellcolor[HTML]{C0C0C0} & \cellcolor[HTML]{C0C0C0} & 2968              & 0.0013            \\ \hline
\cellcolor[HTML]{C0C0C0} & \cellcolor[HTML]{C0C0C0} & \cellcolor[HTML]{C0C0C0} & \cellcolor[HTML]{C0C0C0} & 2939              & 0.0005            \\ \hline \hline
\end{tabular}
\caption[Spillover Example Table]{This table displays an example of the spillover contributions for Healpix bins 2967, 2968 and 2969. The column labeled Cont is the percent contribution to the Receiving Bin, of the giving bin's background.}
\label{tab:spillTable}
\end{table}

A positive error bar on a Healpix bin's background estimate is acquired by summing all of the neighboring Healpix bin's background contributions to a given Healpix bin.  This value is referred to as the inflow.  A negative error bar on a Healpix bin's background estimate is acquired by subtracting a Healpix bin's background contribution to itself from its background estimate.  Thus for Healpix bin $i$, its inflow and outflow are described by Equations \ref{eq:inflow} and \ref{eq:outflow}

\begin{equation} \label{eq:inflow}
I_i = \sum_j bg_j \cdot C_{j\textrm{ to }i}
\end{equation}

\begin{equation} \label{eq:outflow}
O_i = bg_i (1-C_{i\textrm{ to }i})
\end{equation}

Where $I_i$ and $O_i$ are the inflow and outflow of Bin i, $bg_i$ is the background of Bin i, and $C_{j\textrm{ to }i}$ is the contribution of Bin j to Bin i.

\subsubsection{Fit Choice Uncertainty}

For this analysis, the fit model chosen was an exponential function.  It was not, however, the only option.  In order to attempt to take into account any additional systematic uncertainty introduced by the choice of an exponential our LD data is fit by both an exponential function and a power law function.  A power law can fit our data nearly, or possibly just as well as an exponential but results in a systematically higher background estimate.  Figure \ref{fig:expoAndPow} displays both a power law fit and an exponential decay fit to the same Healpix bin's data.  

\begin{figure}[h]
\centering
\includegraphics{../figures/expoAndPow.png}
\caption[Example Exponential and Power-law Fit]{Figure displays both an exponential fit and a power law fit on the same axis, fit to the same set of data.  The data is in black.  The exponential fit is in red.  The power law fit is in blue.  Both the power law fit and the exponential fit fit the data well, while also diverging significantly at high values of the linear combination variable. }
\label{fig:expoAndPow}
\end{figure}
 
A background estimate for a given y-intercept of the linear discriminate cut is calculated from the exponential fit as shown in Equation \ref{eq:bgEst} by integrating the exponential fit from the y-intercept of the linear discriminate cut, CutVal, to infinity.  The same thing is done for the power law.  The equation for a power law is shown in Equation \ref{eq:powfit}.  The equation for the background estimate from a power law fit is shown in Equation \ref{eq:powBg}.

\begin{equation} \label{eq:powfit}
h(x) = a \cdot x^b
\end{equation}

\begin{equation} \label{eq:powBg}
bg_h = \frac{-a}{b+1} V^{b+1}
\end{equation}

Note that Equation \ref{eq:powBg} is only valid when $b < 0$, which should always be the case for our data. 
Once a background estimate is obtained from both fits, the difference between those two fits is taken as a one-sided error bar on our background estimate.  This is nearly always a positive error bar. 
 
\subsubsection{Systematic Uncertainty Values}

These three sources of uncertainty are incorporated into our overall background estimate by generating a background distribution including randomized contributions from each of the systematic errors.  Thus our random background estimate can be represented as follows.

\begin{equation} \label{eq:bgRFull}
BG_{r} = bg_{est} + p_{r} + I_{r} - O_{r} + C_{r}
\end{equation}

Where $bg_{est}$ is the background estimate obtained from integrating the exponential fit above the CutVal, $p_{r}$ is the randomized error from the fit parameter uncertainty, $I_{r}$ and $O_{r}$ are the randomized error from the inflow and outflow, respectively, and $C_{r}$ is the randomized error from the choice of fit model uncertainty.   Note that $p_{r}$ is obtained by subtracting the random background calculated with randomized fit exponential fit parameters from the $bg_{est}$.

\begin{equation}
p_{r} = bg_{est} - bg(a_{r},b_{r})
\end{equation}

Then $I_{r}$ and $O_{r}$ are both obtained by using the built in ROOT function TRandom::Gaus(Mean,Sigma).  Both $I_{r}$ and $O_{r}$ must be only positive, however because they are representing one-sided error bars.  This is handled by taking the absolute value of the number returned by ROOT's Gaus function.

\begin{equation}
\begin{split}
I_{r}  = Abs( Gaus(0,I) ) \\
O_{r} = Abs( Gaus(0,O) )
\end{split}
 \end{equation}

Where $I$ and $O$ are obtained as described in subsection \ref{subsubsec:spillover}.  It is possible (though for all relevant Healpix bins very improbable) for $O_{r}$ to be larger than $bg_{est}$.  If this happens then $o_{r}$ is set to be equal to $bg_{est}$.
  
Finally, $C_{r}$ is obtained by pulling a random value from a log-normal distribution.  The mean of the log-normal distribution is set to be the average of the background estimates obtained from the exponential fit and the power law fit.  The variance of the log-normal distribution is set to be one half the difference between the background estimates from the exponential fit and the power law fit.   The log-normal distribution is described by Equation \ref{eq:logNorm} \cite{logNormal}.

\begin{equation} \label{eq:logNorm}
L(x,\mu,\sigma) = \frac{1}{x \cdot \sigma \cdot \sqrt{2\pi}} \cdot e^{-\frac{(\ln x-\mu)^2}{2 \cdot \sigma^2} }
\end{equation}
Where 
\begin{equation}
\begin{split}
 \sigma = \ln{ \frac{mean^2}{\sqrt{variance+mean^2}} }  \\
\mu = \sqrt{ \ln{ \frac{variance}{mean^2}+1 } } 
\end{split}
\end{equation}

A log-normal is used here to attempt to more accurately model the positive definite nature of this source of error.  This distribution naturally goes to zero at zero and has an extended tail which is typical of one-sided sources of error.  Using Equation \ref{eq:logNorm} in combination with the dartboard method (also known as Monte Carlo Integration) of obtaining a random number from a distribution,  $C_{r}$ is obtained.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/expBgDist.png}
\caption[Example Background Experiment Distribution]{Figure shows a typical background distribution generated from including systematic uncertainties.  Plot shown is for Healpix bin 3004.}
\label{fig:expBgDist}
\end{figure}

Following this procedure, thousands of random backgrounds are created in order to form a distribution for each Healpix bin.  An example of such a background distribution is shown in Figure \ref{fig:expBgDist}.  These distributions are used during our optimization of the linear discriminate cut.  The mean of this distribution is taken as our expected background estimate, including systematics.  The distribution is transformed into a CDF and the point where 15.8\% of the background distribution is below that point is taken as the lower one standard deviation bound.  Similarly, the upper bound is the point when 84\% of the background distribution is below the data point.  These values are reported for all Healpix bins used in our analysis in Tables \ref{tab:bgTableV} (for V-pol) and \ref{tab:bgTableH} (for H-pol)

\begin{table}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/bigBgTableV.png}
\caption[V-pol Passing Healpix bins Table]{Table shows (for V-pol) the final optimized y-intercept cut, unnormalized number of passing sim events, background estimate from just the exponential fit, the background estimate obtained from the distribution created from the inclusion of systematic uncertainties, as well as the uncertainty on that estimate for all passing Healpix bins in the V-pol analysis channel.}
\label{tab:bgTableV}
\end{table}

\begin{table}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/bigBgTableH.png}
\caption[H-pol Passing Healpix bins Table]{Table shows (for H-pol) the final optimized y-intercept cut, unnormalized number of passing sim events, background estimate from just the exponential fit, the background estimate obtained from the distribution created from the inclusion of systematic uncertainties, as well as the uncertainty on that estimate for all passing Healpix bins in the H-pol analysis channel.}
\label{tab:bgTableH}
\end{table}


\subsection{Optimization}

We optimize several aspects of our analysis in order to set the best limit on neutrino models possible.   Before we can talk about our optimizations, however, our figure of merit must be addressed.  Our figure of merit is a scale factor `C'.  

\subsubsection{The Scale Factor C}

The scale factor C is multiplied by the number of events in our simulated neutrino data set to scale the number of neutrinos being predicted by the model we are testing against.  We want to be able to reject the model with the smallest amount of neutrino production possible so that we can set the strongest limit possible.  Thus, in general, we are optimizing by minimizing C.  In order to save computer time, however, when optimizing our linear discriminate cut's y-intercept value we optimize over an analogous quantity, as discussed in Section \ref{subsubsec:optLDcut}.  Our neutrino model is Kotera Max, the upper most simulation line in Figure \ref{fig:anita12limit}.
For a single Healpix bin with a background estimate of $b$ then the likelihood of observing $s$ neutrinos on top of our background is given by Equation \ref{eq:L}

\begin{equation} \label{eq:L}
L(s) = \frac{e^{-(b+s)} \cdot (b+s)^b}{\Gamma(b+1,b)}
\end{equation}

Equation \ref{eq:L} is really just the Poisson equation for a predicted count of $b$ and an observation of $b+s$ with a few simple modifications.  The Poisson equation's normalization of $b!$ becomes $\Gamma(b+1)$ to account for the fact that our events are weighted and thus not always integers.  $\Gamma(b+1)$, the complete gamma function, then becomes $\Gamma(b+1,b)$, the upper incomplete gamma function, to account for the addition of b to s, which alters the integration limits when finding the normalization.  
What we want to know for a given Healpix bin though is not the probability of observing $s$ neutrinos, but of observing more than $s \cdot C$ neutrinos, $P(>s \cdot C)$.

\begin{equation} \label{eq:PBin}
P(>s \cdot C) = \int_{s \cdot C}^{\infty} P(s')ds'
\end{equation}

We want to find C such that the chance of observing more than $s \cdot C$ neutrinos in any Healpix bin is less than 10\%. 

\begin{equation} \label{eq:HowC}
0.1    = \prod_i P(>s_i \cdot C) 
\end{equation}

Where $s_i$ is the unnormalized amount of signal passing the ith bin's cuts given our Kotera Max neutrino model.  

\subsubsection{Past Optimizations} \label{subsubsec:slopeOptimization}

During Sam Stafford's analysis of the same 10\% ANITA-III data set that is used as a training sample in this analysis, three parameters were optimized for simultaneously by minimizing C.  The first two parameters optimized for were the circular polarization strength threshold and circular polarization separation threshold used by the C-pol cut's Sam introduced to the Binned Analysis.  The third parameter was the linear discriminate cut's slope.  This analysis is using the values Sam's analysis optimized those parameters to.  Their values are given in Section \ref{subsec:facuts}.
 
\subsubsection{Optimizing the Linear Discriminate Cut} \label{subsubsec:optLDcut}

The optimization of the linear discriminate cut's y-intercept (aka cutVal) does not use C.  This is because the calculation of C requires all of the Healpix bins and this optimization is done for each bin individually.  A similar method is used, however.  If $S_{up}$ is the amount of signal that we can reject with 90\% confidence for a single Healpix bin, and $s$ is the amount of signal predicted by a model, then imagine what it means if $s = S_{up}$.  It would mean that we could just barely reject the model.  If however, $s > S_{up}$, it means we could not only reject the model that gave us $s$ but that we could scale $s$ down some by some scale factor $C$ and we would still be able to reject the model.  Thus what we want is to maximize how much larger than $S_{up}$ $s$ is, so that we can have as low of a value for C as possible.  This means that what we will actually be doing to optimize our linear discriminate cut, per Healpix bin, is maximizing $s/S_{up}$.

Both the background estimate $b$ and the amount of passing simulated neutrinos $s$ depend on the cutVal.  Many different possible values for cutVal are tested.  For each one of these values, $s$ and $b$ are calculated.  The signal $s$ is just found by counting the number of simulated events that pass the linear discriminate cut (and all previous cuts) for the value of cutVal being tested.  In order to take into account the systematic uncertainties in the estimation of $b$, many different random backgrounds are calculated using Equation \ref{eq:bgRFull}.  Each of these random backgrounds creates a different likelihood function.

\begin{equation} \label{eq:L_i}
L_i(s,b_i) = \frac{e^{-(b_i+s)} \cdot (b_i+s)^b_i}{\Gamma(b_i+1,b_i)}
\end{equation}

Where $b_i$ is the i$^{th}$ random background.  A smeared likelihood function is created by summing over the different likelihood functions.

\begin{equation} \label{eq:L_smear}
L_{smear}(s) = \frac{1}{N} \sum_{i=0}^N L_i(s,b_i)
\end{equation}

This smeared likelihood function accounts for the effects of the systematic uncertainties in the background estimate.  Figure \ref{fig:LandLsmear} shows an example likelihood $L(s)$ in red, calculated with the background estimate with no systematic uncertainties, and an example smeared likelihood $L_{smear}(s)$ in blue, calculated using thousands of random backgrounds.  
 
\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/LandLsmear.png}
\caption[Example Likelihood and Smeared Likelihood Functions]{Plot shows the effect of smearing one of our likelihood functions with the inclusion of systematic uncertainty.  The unsmeared likelihood is in red, while the smeared likelihood function is in blue. The red vertical line is the value of $S_{up}$ found with the smeared likelihood function.}
\label{fig:LandLsmear}
\end{figure}

Similar to how C was calculated, $S_{up}$ is now calculated such that only 10\% of the likelihood function (now the smeared likelihood function) lies above $S_{up}$

\begin{equation} \label{S_up}
0.1    = \int_{S_{up}}^{\infty} L_{smear}(s') ds'
\end{equation}

Figure \ref{fig:sAndSup} shows a typical data for $s$ and $S_{up}$ plotted against cutVal.  Figure \ref{fig:s/sup} shows a typical plot of $s/S_{up}$ plotted against cutVal.  As mentioned earlier, the optimal value for cutVal is when $s/S_{up}$ is its maximum.  Plots of $s/S_{up}$ vs cutVal generally have a strong peak, as shown in Figure \ref{fig:s/sup}.  Both Sam Stafford's ANITA-III analysis and Brian Dailey's ANITA-II analysis optimized for the best possible cutVal per bin as well, however, their analysis did not include systematic uncertainties.  In general, the addition of systematic uncertainties causes the optimization to find higher linear discriminate cut y-intercept values.  This, in turn, reduces both the background estimates and the chances of background events passing our analysis cuts. 

\begin{figure}[h]
\centering
\includegraphics{../figures/sAndSup.png}
\caption[Example plot of $s$ and $s_{up}$]{Plot displays both $s$ (in blue) and $s_{up}$ (in red) plotted on the same axis.  Healpix bin 3004 for the V-pol channel is plotted here.}
\label{fig:sAndSup}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics{../figures/soversup.png}
\caption[Example plot of $s/s_{up}$]{Plot displays $s/s_{up}$.  The peak of this plot is this Healpix bin's optimized y-intercept cut value.  Healpix bin 3004 for the V-pol channel is plotted here.}
\label{fig:s/sup}
\end{figure}

\subsubsection{Optimizing the Linear Discriminate Cut over all Healpix Bins} \label{subsubsec:optLDCutOverall}

Though we have already optimized each individual Healpix bin's y-intercept value for its linear discriminate cut (or cutVal), none of those optimizations take into consideration the bigger picture.  We want to optimize for the best overall limit possible, not the best possible individual limits in each Healpix bin.  In order to correct for this, we allow all of the passing Healpix bins' cutVals to shift up and down together.   The overall shift that returns the lowest value for C is used, and all Healpix bins' background estimates and the number of passing simulated events are reevaluated to reflect this change.  This overall cutVal optimization happens before Healpix bins are cut for either having too much background or low sensitivity.  

In most cases, this increases the cutVal for each bin by less than 0.3, sometimes not changing the final value at all.  Increases in the cutVal reduces our background estimates and strengthens the linear discriminate cuts.  For both our H- and V-pol Healpix orientations the overall shift is 0.0.

\subsubsection{Optimizing for Healpix Orientation}

Our initial Healpix bin placement was simply chosen because it was the default.  It is possible however that a more ideal orientation exists.  If for example, a large source of anthropogenic noise was near the boundaries between Healpix bins it could lead to a large number of weighted background events spread between two Healpix bins instead of centered inside of one bin.  This would worsen our ability to find neutrinos in both Healpix bins and could cause the exponential fits to be worse in both bins.  It would also increase the systematic uncertainty in both bins.  Thus it is believed some Healpix orientations could be more ideal than others. 

In order to account for this, the analysis is performed for 100 different varying orientations with different shifts in longitude and latitude.  The approximate size of a single Healpix bin is 5.6 degrees wide in longitude, and 5.6 degrees wide in latitude.  We sampled a grid of shifts in both longitude and latitude.  Ten different shifts were tested for each, with step sizes of 0.56 degrees.  The scale factor, C, was calculated (with the inclusion of systematic uncertainties) for each of the possible 100 orientations and the orientation that yielded the lowest value was selected.  Table \ref{tab:healpixV} and \ref{tab:healpixH} show a color-coded table of the values for C retrieved from the different orientations for V-pol and H-pol channels respectively.  In V-pol this resulted in an approximate 20\% reduction in C.  In H-pol this optimization resulted in an approximate 30\% reduction in C.  These reductions will directly translate to a lower limit.

\begin{table}[h]
\centering
\includegraphics[width=0.9\linewidth]{../figures/healpixTableV.png}
\caption[V-pol Healpix Optimization Table]{Table shows the values of C returned by varying offsets in longitude and latitude for the Healpix orientation in the V-pol channel.  More green and lower values are better.  More red and higher values are worse.}
\label{tab:healpixV}
\end{table}

\begin{table}[h]
\centering
\includegraphics[width=0.9\linewidth]{../figures/healpixTableH.png}
\caption[H-pol Healpix Optimization Table]{Table shows the values of C returned by varying offsets in longitude and latitude for the Healpix orientation in the H-pol channel.  More green and lower values are better.  More red and higher values are worse.}
\label{tab:healpixH}
\end{table}





\chapter{Discussion and Conclusions}

Analysis of the 10\% dataset is now complete. Cuts are set. The linear discriminate cut has been optimized for all Healpix bins for both the H-pol and V-pol channels.  Background estimates for the 90\% sample have been estimated. One event has been found passing our 10\% sample.  The analysis of our low sensitivity Healpix bin sideband and the 90\% sample H-pol channel is underway.  A complete unblinding and examination of the 90\% sample V-pol channel is forthcoming.  This section outlines the results from our 10\% dataset, our sidebands and our H-pol channel, as well as discussing what comes next.

\section{Results with the 10\% data set}

Tables \ref{tab:bgTableV} and \ref{tab:bgTableH} show our final background estimates, optimized linear discriminate cut y-intercepts, and the number of (unnormalized) simulated neutrinos passing our final cuts. With our final cuts tuned, we see one V-pol event passing and 0 H-pol event passing.

\subsection{Events Passing in our 10\% data set}

The event passing in our 10\% dataset shows characteristics of a payload blast event. The events and some key information about each of them can be found in Table \ref{tab:passingTable}. For comparison, Sam Stafford's analysis saw three V-pol and five H-pol events passing in his 10\% sample \cite{sam}. The addition of the satellite stripe cut removed many of those events. The addition of systematic uncertainties also increased optimized cutVals which created more stringent cuts.  More work on the payload blast quality cut should be done in the future.

\begin{table}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/passingTable.png}
\caption[Passing Events Table, 10\% dataset]{Table shows events passing in both H and V-pol analysis channels.}
\label{tab:passingTable}
\end{table}

\section{Analysis Efficiency}


Based on our 10\% dataset we can estimate the efficiency of our analysis compared to Brian Dailey's ANITA-II binned analysis and Abby Vieregg's ANITA-II Clustering analysis.  Figure \ref{fig:A2eff} shows the efficiency curves for both ANITA-II analyses.  Figure \ref{fig:A3eff} shows the efficiency curves for passing H-pol Healpix bins.  This analysis appears to on average achieves an efficiency turn on at lower SNR and a sharper efficiency rise than the ANITA-II analyses.  Over all this means our analysis is more efficient that the past binned analysis.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/a2eff.png}
\caption[ANITA-II Analysis Efficiency]{In black is the SNR vs efficiency curve for the ANITA-II clustering analysis.  Other lines are the SNR vs efficiency curves for individual Healpix bins in the ANITA-II binned analysis.  Figure credit to Oindree Banerjee.}
\label{fig:A2eff}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/a3eff.png}
\caption[ANITA-III Binned Analysis Efficiency]{Figure shows efficiency vs SNR curves for passing H-pol Healpix bins.  Efficiency calculation does not include loss from quality cuts, which should be negligible at high SNR.  Data at SNR $>$ 20 is shown as a rolling average (of 2) to help to counteract the lack of data at high SNRs.}
\label{fig:A3eff}
\end{figure}

\section{Results from our 90\% sideband data set}

As mentioned in Section \ref{subsec:facuts}, The Healpix bins that together account for 1\% of the sensitivity are set aside to be used as a sideband.  We do not expect to see a neutrino in them, because they have such low sensitivity, but they should have typical background events.  The sideband bins used are Healpix bins 3009 and 3047 in H-pol, and Healpix bins 3001, 3008, 3009 and 3011 in V-pol.  In H-pol, 11 events are observed to pass our LD cut, all in Bin 3009.  In V-pol, 2 events are observed to pass our LD cut, one in 3001, and one in 3011. Table \ref{tab:sidebandPassing} shows all 13 events.

\begin{table}[h]
\centering
\includegraphics[width=1.0\linewidth]{../figures/sidebandPassing.png}
\caption[Events passing LD Cut in sideband Healpix Bins]{Table shows Events passing the LD cut in 90\% dataset sideband Healpix bins.  All H-pol events cluster with one another.  Both V-pol events appear to be payload blasts.}
\label{tab:sidebandPassing}
\end{table}

All 11 of the H-pol events are found to cluster within 40 km of at least 9 of the other H-pol events.  A German research base is known to be in that area of the ice.  A clustering cut would remove all 11 H-pol events.  Both of the V-pol events appear to be payload blast like, which is further evidence that our analysis's payload blast cut needs refinement.

\section{Results from out 90\% H-pol data set}

In the full 90\% H-pol data set, 6 events are observed to pass.  Two of them are observed by other analysis and are believed to be cosmic ray events.  Three of them appear to be payload blasts.  One does not fall into either of those categories but also does not appear to be strongly impulsive.  Table \ref{tab:hpolPassing} shows all 6 passing H-pol events.  Other ANITA-III analysis have found upwards of 20 CR candidates, our analysis, however, unfortunately, has a rather poor sensitivity to H-pol events because so few H-pol Healpix bins pass.  Using a larger training data set or loosening requirements on the amount of data needed to attempt a fit or combining Healpix bins could help this in the future.

\begin{table}[h]
\centering
\includegraphics[width=0.8\linewidth]{../figures/hpolPassing.png}
\caption[Events passing LD Cut in 90\% H-pol sample]{Table shows events passing the LD cut in the 90\% data set H-pol channel.  Two events were observed by other analyses and are cosmic ray candidates.  Three are believed to be payload blasts.  Once event, 36975694, required further investigation.  The Data Set column is which 10\% slice of the 90\% data set the event fell into, numbered 0 through 9.}
\label{tab:hpolPassing}
\end{table}

\section{Discussion}

The 10\%, H- and V-pol sideband, and 90\% H-pol datasets have been examined.  Payload blasts are observed passing in all three of our examined data sets.  This implies a better cut is needed for them in the future.  Though we see no events clustering in our 90\% H-pol dataset, we see 11 clustering in a single Healpix bin from our H-pol sideband Healpix bin 3009.  The German base located there appears to be the second brightest spot in Antarctica for our analysis just before the LD cut.  The first being McMurdo Station.  This might imply areas with a large production of anthropogenic noise may be insufficiently modeled by a 10\% data set using our methods.  Clustering removes these events and appears to be necessary for our analysis to deal with Healpix bins with very large anthropogenic contributions.

In most cases for Healpix bins examined in both the 10\% and 90\% datasets, our fits match the observed distributions well.  Even in the case of H-pol Healpix bin 3009, a low statistics tail is what emerges to lead to the 11 passing events, while the bulk of the distribution is well modeled by our exponential fit.  I think this shows our method of fitting the 10\% data set to estimate the 90\% dataset works well in most cases.  Figure \ref{fig:1090bad} shows the LD distributions for H-pol Healpix bin 3009 from the 10\% and 90\% datasets side by side, while Figure \ref{fig:1090good} shows the LD distributions for H-pol Healpix bin 3031 from the 10\% and 90\% datasets side by side.  Healpix bin 3009 is the worst case of our background estimate failing to predict 90\% data distribution, while Healpix bin 3031 shows a result with a good match. For most other Healpix bins' 10\% and 90\% distributions match more similarly to Healpix bin 3031 than 3009 in this regard. 

\begin{figure}[h]
\centering
\includegraphics[width=1.0\linewidth]{../figures/1090bad.png}
\caption[10\% and 90\% LD distributions for Healpix bin 3009]{The 10\% dataset and 90\% dataset LD distributions side by side.  The 10\% is on the left, while the 90\% is on the right.  The red diagonal line is the exponential fit to the 10\% data.  In the 90\% data is has been scaled up by a factor of 9.  The red vertical line is the LD cut value for this Healpix bin.  The 90\% data shows a long tail for this bin not observed in the 10\% data set.}
\label{fig:1090bad}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=1.0\linewidth]{../figures/1090good.png}
\caption[10\% and 90\% LD distributions for Healpix bin 3031]{The 10\% dataset and 90\% dataset LD distributions side by side.  The 10\% is on the left, while the 90\% is on the right.  The red diagonal line is the exponential fit to the 10\% data.  In the 90\% data is has been scaled up by a factor of 9.  The red vertical line is the LD cut value for this Healpix bin.  The 10\% and 90\% data sets match remarkably well for this Healpix bin.}
\label{fig:1090good}
\end{figure}

The excess of passing events that both Brian Dailey and Sam Stafford's analyses observed appears to be mostly resolved.  For reference, Brian's analysis saw approximately 20 times as many events as we do in our low sensitivity Healpix bins.  He saw approximately three times as many events in his 90\% H-pol sample.  Sam never opened any further data sets, but saw 6 times as many events passing in his 10\% sample as we do.  We do have a handful of payload blast-like events passing, but overall the addition of systematic uncertainty to our optimization and the satellite stripe cut has served its purpose and greatly reduced the number of events observed to be passing while only sacrificing approximately 12\% of our nuetrino sensitivity (before LD cuts) when compared to Sam's analysis.


\section{Future Analysis Improvements}
In a future iteration of the binned analysis, many additional things can be done to further improve our results.

\subsection{Improved Payload blast cut}

There is evidence that out payload blast cut needs to be improved.  All examined datasets show payload blast-like events passing.  

\subsection{Definition of SNR}

The method we are using to calculate SNR has been shown to be less precise than more modern methods since our analysis began. We are using the early part of the waveform to estimate the noise, however in ANITA-III the early part of the waveform is very short. An alternate method has been developed by collaborators, which calculates the SNR from nearby noise events. Switching the entire analysis over to using an alternate definition of SNR could have wide-reaching effects, because our primary cut, the linear discriminate cut, is a linear combination of SNR and correlation peak.

\subsection{Size of the Training Data Set}

We use 10\% of the total data to train our analysis cuts. However, it is possible that using more of the data would be more optimal. Having more data to fit will result in more accurate and robust background estimates. The percent of the data should be used for training has not been looked into in detail, and should be investigated.

\subsection{Rigidity}

One concern we have with our method of obtaining our background estimate is the effects a single outlying event can have. It appears that roughly 50\% of Healpix bins rejected for having a p-value of less than 0.05 have a single event with a high linear combination value. This may mean that we are rejecting Healpix bins due to candidates being in them. One way to deal with this is to always exclude the largest event, and add an additional systematic uncertainty to our background estimate based on how much excluding that event changed the fit. This should prevent any Healpix bins from being rejected by outliers and give us some insight into how much an outlier is affecting our background estimate.

\subsection{Optimizing for Sensitivity}

We currently optimize our analysis to set the best limit on neutrino models assuming we see a number of events passing consistent with our background. In the future, we may want to instead optimize to maximize our chance of detecting a neutrino.

\subsection{Gerrymandering our Healpix bins}

Though right now we are using equal area Healpix bins, that is not an important feature of our analysis.  Each bin already has a different sensitivity to neutrinos due to variations in ice thickness and how long ANITA observed that ice.  In the future, we may want to create more finely spaced Healpix bins, then combine bins with neighbors until we are able to get a usable background estimate from the new, oddly shaped area.  This could potentially allow us to keep more of ice we are currently rejecting with our Healpix bin cut.  
